{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer ##how we handle missing values\n",
    "from sklearn.compose import ColumnTransformer ##Transform our data features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SD DUI Crash Data\n",
    "SD_DUIs_df = pd.read_csv(\"/mnt/c/Users/tbrag/OneDrive/Desktop/bda602venv/SD DUI Filtered.csv\")\n",
    "\n",
    "##LA DUI Crash Data\n",
    "LA_DUIs_df = pd.read_csv(\"/mnt/c/Users/tbrag/OneDrive/Desktop/bda602venv/LA DUI Filtered.csv\")\n",
    "\n",
    "# Concatenate the two colision Dataframes vertically\n",
    "all_dui_df = pd.concat([SD_DUIs_df, LA_DUIs_df])\n",
    "\n",
    "# Reset the index of the combined DataFrame\n",
    "all_dui_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Assuming 'Latitude' and 'Longitude' columns exist in your DataFrame\n",
    "geometry = [Point(xy) for xy in zip(all_dui_df['LONGITUDE'], all_dui_df['LATITUDE'])]\n",
    "DUI_gdf = gpd.GeoDataFrame(all_dui_df, geometry=geometry)\n",
    "DUI_gdf.set_crs(\"EPSG:4326\")\n",
    "\n",
    "##load census data\n",
    "SD_Census = pd.read_csv(\"/mnt/c/Users/tbrag/OneDrive/Desktop/bda602venv/SD data.csv\")\n",
    "\n",
    "LA_Census = pd.read_csv(\"/mnt/c/Users/tbrag/OneDrive/Desktop/bda602venv/LA data.csv\")\n",
    "\n",
    "# Concatenate the census Dataframes vertically\n",
    "all_census_df = pd.concat([SD_Census, LA_Census])\n",
    "all_census_df.head(5)\n",
    "\n",
    "#all_census_df['geometry'] = all_census_df['geometry'].apply(wkt.loads)\n",
    "#Census_gdf = gpd.GeoDataFrame(all_census_df, geometry='geometry')\n",
    "#Census_gdf.set_crs(\"EPSG:4326\")\n",
    "\n",
    "#DUI_gdf.crs = \"EPSG:4326\"\n",
    "#Census_gdf.crs = \"EPSG:4326\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_points_in_polygons(points, polygons, polygon_id, new_column=\"points_count\"):\n",
    "\n",
    "    # Save the index to restore it later\n",
    "    original_index = polygons.index\n",
    "\n",
    "    # Ensures polygon_id is not the index but a column\n",
    "    if original_index.name == polygon_id:\n",
    "        polygons = polygons.reset_index()\n",
    "\n",
    "    # Count points in polygons\n",
    "    points_in_polygon = (\n",
    "        # Spatial join associates points and polygons that intersects each other\n",
    "        polygons.sjoin(\n",
    "            points,\n",
    "            how=\"inner\",  # Only keep points that matches a polygon\n",
    "            op='intersects',\n",
    "        )\n",
    "        .groupby(polygon_id)  # Group points by polygons\n",
    "        .size()  # Get number of points\n",
    "        .rename(new_column)  # Name your column as you want it to appear in polygons\n",
    "    )\n",
    "\n",
    "    # Add count series to the polygons dataframe\n",
    "    polygons = (\n",
    "        polygons.set_index(polygon_id)  # Ensures the index is the same as points_in_polygons\n",
    "        .join(\n",
    "            points_in_polygon,\n",
    "            how=\"left\",  # Keep polygons containing no points\n",
    "        )\n",
    "        .fillna({new_column: 0})  # Fill NaN with 0\n",
    "    )\n",
    "\n",
    "    if original_index.name != polygon_id:\n",
    "        # Avoids duplicating polygon_id as column and index\n",
    "        polygons = polygons.reset_index()\n",
    "\n",
    "    polygons = polygons.set_index(original_index) # Restore the original index\n",
    "\n",
    "    return polygons\n",
    "new_df = count_points_in_polygons(DUI_gdf, Census_gdf, 'tract', new_column=\"points_count\")\n",
    "\n",
    "# Count the number of rows\n",
    "num_rows = len(new_df)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "\n",
    "# Sum the dui_count column\n",
    "dui_count_sum = new_df['points_count'].sum()\n",
    "print(f\"Sum of DUI counts: {dui_count_sum}\")\n",
    "\n",
    "new_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['AIRLINE','ORIGIN','DEST','DISTANCE','ori_TMIN','ori_TMAX','ori_SNOW','ori_SNWD','ori_AWND','ori_PRCP','dest_TMIN','dest_TMAX','dest_SNOW','dest_SNWD','dest_AWND','dest_PRCP','15_DELAYED','year','month','day','hour','day_of_week']\n",
    "\n",
    "# Drop all columns except the specified ones\n",
    "df= new_df.drop(columns=new_df.columns.difference(columns_to_keep))\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract Numeric Features\n",
    "numeric_features = fw_data_final.select_dtypes(\n",
    "    include=[\"float\",\"int\"]\n",
    ")\n",
    "\n",
    "categorical_features = fw_data_final.iloc[:,~fw_data_final.columns.isin(numeric_features.columns.values)]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda602",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
